# Big Data - Final Project - 2018/2019
## Master's degree in Computer Science and Engineering - UniVr

### Relazione con tutte le spiegazioni in merito al progetto
Disponibile qui: https://github.com/marcocrosara96/bigdata-final-project/blob/master/Relazione.pdf

### Link utili e riferimenti usati nel progetto
- Dataset Search: https://toolbox.google.com/datasetsearch
- February 2019 crawl archive now available – Common Crawl: http://commoncrawl.org/2019/03/february-2019-crawl-archive-now-available/
- August Crawl Archive Introduces Language Annotations – Common Crawl: http://commoncrawl.org/2018/08/august-2018-crawl-archive-now-available/
- Common Crawl February 2019 Crawl Archive (CC-MAIN-2019-09): https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-09/index.html
- 1,000 Most Common Words in Different Languages (with Audio): https://www.101languages.net/common-words/
- 1000 Most Common Words: http://1000mostcommonwords.com/
- Word list download - English, Spanish, French, German | Sketch Engine: https://www.sketchengine.eu/word-lists/
- Custom Input Format in Hadoop | Acadgild best hadoop online materials: https://acadgild.com/blog/custom-input-format-hadoop
- mapreduce - Input split and block in hadoop - Stack Overflow: https://stackoverflow.com/questions/37065242/input-split-and-block-in-hadoop
- How does Hadoop process records split across block boundaries? - Stack Overflow: https://stackoverflow.com/questions/14291170/how-does-hadoop-process-records-split-across-block-boundaries
- Custom input split and custom NLineInputFormat Record in Hadoop | Dpayne Dudhe: https://dpaynedudhe.wordpress.com/2015/10/23/custom-input-split-and-custom-nlineinputformat-record-in-hadoop/
- Apache Hadoop Distributed Cache Example | Examples Java Code Geeks - 2019: https://examples.javacodegeeks.com/enterprise-java/apache-hadoop/apache-hadoop-distributed-cache-example/
- Wiktionary:Frequency lists - Wiktionary: https://en.wiktionary.org/wiki/Wiktionary%3aFrequency_lists#Japanese

### Comandi utili
- docker start cloudera
- docker cp out/analyzer.jar cloudera:/DATA
- docker exec -it cloudera /bin/bash
- su cloudera
- hadoop jar DATA/analyzer.jar
- yarn resourcemanager
